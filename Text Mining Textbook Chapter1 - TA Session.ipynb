{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.book import *\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn Python Tricks and Basic NLTK Functions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Sense and Sensiblity ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sense and Sensibility is set in southwest England, London and Kent between 1792 and 1797, and portrays the life and loves of the Dashwood sisters, Elinor and Marianne. \"Sense\" in the book means good judgment or prudence, and \"sensibility\" means sensitivity or emotionality. \"Sense\" is identified with the character of Elinor, while \"sensibility\" is identified with the character of Marianne..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TA session goals:\n",
    "   * Introducing basic Python tricks useful for manipulate strings\n",
    "   * List comprehension\n",
    "   * Use the functions we've learned to conduct simple analysis of two different novel characters\n",
    "   * Concept of functions\n",
    "   * Variations of basic functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python: Fancy Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L = list(range(10)) #not inclusive\n",
    "print(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L[::2] # get even numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L[1:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L[1:8:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python: String Manipulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Strip \n",
    "s = \"I don't need the white space_        \"\n",
    "s.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Nor do I need '_'\n",
    "s = \"I don't need the white space_        \"\n",
    "s.strip().strip('_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Case transformation\n",
    "\n",
    "s = \"sensibility\"\n",
    "print(s.upper(), s.capitalize(), s.upper().lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# De-punctuate a string\n",
    "\n",
    "s = \"Not that you have any reason to regret , my dear Elinor .\"\n",
    "print(s)\n",
    "s = s.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "print(s)\n",
    "l = s.split()\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reverse a string\n",
    "\n",
    "s = \"hello\"\n",
    "s = s[::-1]\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Join a list of words into a string\n",
    "\n",
    "str = ' '.join([\"angry\",\"birds\"])\n",
    "print(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# % string formatting and escape character\n",
    "\n",
    "name = 'Lingwei'\n",
    "coffee = 4\n",
    "text = ('Hello %s, you\\'ve had %i cups of coffee'\n",
    "        % (name, coffee))\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# new_list = [doSomething(item) for item in a_list if condition(item)]\n",
    "\n",
    "[w for w in text2 if len(w) >= 15 and (\"ee\") not in w]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK: Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tokens\n",
    "\n",
    "text2[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Concordance \n",
    "\n",
    "text2.concordance(\"Marianne\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Specifiy n lines to view\n",
    "\n",
    "text2.concordance('Marianne',lines=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Change the left and right context width to n characters\n",
    "\n",
    "text2.concordance('Marianne',50,lines = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find all words sharing a common conext\n",
    "\n",
    "text2.similar('Marianne')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find the common contexts shared by two words\n",
    "\n",
    "text2.common_contexts(['Elinor','Marianne'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK: Counting & Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Count word occurences\n",
    "\n",
    "text2.count('Elinor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text2.count('Marianne')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Frequency\n",
    "\n",
    "# create a new data object that contains info about word frequency\n",
    "\n",
    "fd = nltk.FreqDist(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Simple statistics: Find the top n most common words\n",
    "\n",
    "fd.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Simple statistics: Find the frequency of a word\n",
    "\n",
    "fd['sister']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Simple statistics: Make a cummulative frequency plot: the proportion of the most frequent 50 words\n",
    "\n",
    "fd.plot(50,cumulative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Simple statistics: Find words that occurred only once (hapaxes)\n",
    "\n",
    "rare = fd.hapaxes()\n",
    "print(rare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text2.dispersion_plot(['Elinor','Marianne'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# De-punctuation and de-uppercaseify\n",
    "\n",
    "[w.lower() for w in text2 if w.isalpha()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Searching "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find words that end with ...\n",
    "\n",
    "l = [w for w in text2 if w.endswith('bility')]\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find words that starts with ...\n",
    "\n",
    "[w for w in text2 if w.startswith('ee')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find words that contains ...\n",
    "\n",
    "l = [w for w in text2 if 'dddd' in w]\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# collocations: frequent word combinations\n",
    "\n",
    "text2.collocations()\n",
    "text2.collocations(num=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Bigrams\n",
    "\n",
    "nltk.bigrams(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tri-grams\n",
    "\n",
    "nltk.trigrams(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# n-grams\n",
    "\n",
    "nltk.ngrams(text2,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Work with your own texts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file = open('/Users/weiwei/Desktop/sampletext.txt')\n",
    "chapter1 = file.read();\n",
    "tokens = nltk.word_tokenize(chapter1)\n",
    "print(tokens[:10])\n",
    "text = nltk.Text(tokens)\n",
    "print(type(text))\n",
    "print(text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
