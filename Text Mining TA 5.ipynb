{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mining The Social Web \n",
    "\n",
    "## http://chimera.labs.oreilly.com/books/1234000001583/ch01.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract data from pdf\n",
    "\n",
    "* tabula: extract data from pdf http://tabula.technology/\n",
    "* pdftotext: use on linux\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract data from website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib.request, time, re, random, hashlib\n",
    "from bs4 import BeautifulSoup \n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.spatial.distance import cosine\n",
    "from itertools import combinations\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.spatial import distance\n",
    "%matplotlib osx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IMPORTANT:  PLEASE USE THE FOLLOWING fetch(url) TO LOAD ALL YOUR \n",
    "# WEBPAGES. PLEASE DO NOT DIRECTLY LOAD PAGES. THIS WILL ENSURE THAT\n",
    "# PAGES ARE CACHED AS FILES IN YOUR DIRECTORY, AND AVOID UNNECESSARY\n",
    "# LOAD ON WEBSITES.  ALSO WHEN PAGES ARE ACTUALLY LOADED, THE REQUESTS\n",
    "# ARE STAGGERED AS EXPECTED OF HUMAN BROWSING.\n",
    "\n",
    "# Compassionate Caching inspired by \n",
    "# http://lethain.com/an-introduction-to-compassionate-screenscraping/\n",
    "\n",
    "last_fetched_at = None\n",
    "\n",
    "def fetch(url):\n",
    "    \"\"\"Load the url compassionately.\"\"\"\n",
    "    \n",
    "    global last_fetched_at\n",
    "    \n",
    "    url_hash = hashlib.sha1(url.encode()).hexdigest()\n",
    "    filename = 'cache-file-{}'.format(url_hash)\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            result = f.read()\n",
    "            if len(result) > 0:\n",
    "                print(\"Retrieving from cache:\", url)\n",
    "                return result\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    print(\"Loading:\", url)\n",
    "    wait_interval = random.randint(3000,10000)\n",
    "    if last_fetched_at is not None:\n",
    "        now = time.time()\n",
    "        elapsed = now - last_fetched_at\n",
    "        if elapsed < wait_interval:\n",
    "            time.sleep((wait_interval - elapsed)/1000)\n",
    "        \n",
    "    user_agent = 'Mozilla/5.0 (Windows NT 6.1; Win64; x64)'\n",
    "    headers = { 'User-Agent' : user_agent }\n",
    "    req = urllib.request.Request(url, headers = headers)\n",
    "    last_fetched_at = time.time()\n",
    "    with urllib.request.urlopen(req) as response:\n",
    "        result = str(response.read())\n",
    "        with open(filename, 'w') as f:\n",
    "            f.write(result)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Entity(object):\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.words = None\n",
    "        self.vector = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_search_results(entity):\n",
    "    \"\"\"Return an html with search results for given entity.\"\"\"  \n",
    "    name = entity.name\n",
    "    url_encoded_name = name.replace(' ', '%20')\n",
    "    result = fetch('http://www.usatoday.com'+ '/search/' + url_encoded_name + '/')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_articles(results_html, n=3):\n",
    "    \"\"\"Return a list of article htmls for given search results html.\"\"\"\n",
    "    soupify_result = BeautifulSoup(results_html, 'html.parser')\n",
    "    link_results = soupify_result.find_all('a', attrs={'class':'search-result-item-link'})\n",
    "    domain = 'http://www.usatoday.com'\n",
    "    articles = []\n",
    "    num_result = 0\n",
    "    for link in link_results:\n",
    "        # this excludes any video, audio results\n",
    "        if (link['href'].startswith('/story') and num_result < n):\n",
    "            # the links are relevant links, convert them to absolute links\n",
    "            article = fetch(domain+link['href'])\n",
    "            articles.append(article)\n",
    "            num_result += 1\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "\n",
    "def get_words(articles):\n",
    "    \"\"\"Return list of representative words from a list of article htmls.\"\"\"\n",
    "    bag_of_words = []\n",
    "    for article in articles:\n",
    "        soupify_article = BeautifulSoup(article,'html.parser')\n",
    "        paragraphs = soupify_article.find_all('p',attrs={'class':None})\n",
    "        for p in paragraphs:\n",
    "            if p.parent.name != 'a':\n",
    "                words = word_tokenize(p.text)\n",
    "                filtered_words = [w.lower() for w in words if w.isalpha()]\n",
    "                filtered_stop_words = [w for w in filtered_words if w not in stopwords.words('english')]\n",
    "                bag_of_words += filtered_stop_words\n",
    "        \n",
    "    bag_of_words = set(bag_of_words)\n",
    "    return bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bag_of_words(entity):\n",
    "    results = get_search_results(entity)\n",
    "    articles = get_articles(results,3)\n",
    "    return get_words(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: http://www.usatoday.com/search/hillary%20clinton/\n",
      "Loading: http://www.usatoday.com/story/news/politics/elections/2016/2016/02/02/cruz-topples-trump-clinton-sanders-await-final-tally/79685690/\n",
      "Loading: http://www.usatoday.com/story/news/politics/onpolitics/2016/02/02/hillary-clinton-new-hampshire-iowa-democrats/79700614/\n",
      "Loading: http://www.usatoday.com/story/news/politics/elections/2016/2016/02/03/young-supporters-drive-sanders-virtual-tie-clinton/79739492/\n",
      "{'jeffrey', 'folks', 'laughter', 'loss', 'respective', 'registering', 'since', 'showed', 'city', 'helped', 'won', 'theme', 'declined', 'worked', 'focus', 'ames', 'reminded', 'economic', 'slimmest', 'embarrassment', 'volunteers', 'nashua', 'photo', 'juggernaut', 'questions', 'revolution', 'age', 'separating', 'number', 'polling', 'cedar', 'maryland', 'move', 'strong', 'error', 'described', 'ago', 'thus', 'willing', 'vote', 'jubilant', 'reflection', 'big', 'total', 'together', 'introduced', 'sound', 'worth', 'political', 'result', 'consortium', 'already', 'states', 'part', 'sure', 'represented', 'decision', 'believe', 'attention', 'lost', 'clinton', 'see', 'freely', 'thanked', 'changing', 'locking', 'billed', 'delegate', 'look', 'ted', 'massachusetts', 'also', 'first', 'preaching', 'reported', 'spending', 'think', 'keene', 'racked', 'advertising', 'combined', 'good', 'important', 'credit', 'caucuses', 'unsuccessful', 'hardy', 'conclusion', 'comes', 'rural', 'shot', 'policies', 'surprised', 'jackson', 'room', 'way', 'least', 'continues', 'god', 'deficit', 'directly', 'pays', 'michael', 'outlets', 'incredible', 'margin', 'triumphantly', 'register', 'grassroots', 'adorned', 'stone', 'organizational', 'candidate', 'president', 'winner', 'heavy', 'point', 'ages', 'counties', 'possible', 'rania', 'easily', 'map', 'infused', 'arrived', 'pool', 'fervently', 'ensuing', 'democrats', 'exit', 'believed', 'nearly', 'tell', 'expected', 'encompassing', 'lead', 'secretary', 'takes', 'words', 'harshest', 'spokeswoman', 'stand', 'illness', 'coverage', 'spent', 'thing', 'chris', 'contrast', 'course', 'something', 'ducking', 'workers', 'enjoyed', 'completely', 'claim', 'last', 'party', 'closest', 'major', 'ended', 'strongholds', 'january', 'stronger', 'still', 'leads', 'agriculture', 'texas', 'younger', 'owes', 'avoided', 'lieutenant', 'play', 'older', 'nevada', 'years', 'neighboring', 'large', 'metro', 'treasurer', 'brian', 'upcoming', 'claimed', 'change', 'showing', 'power', 'precincts', 'riding', 'supported', 'gap', 'falls', 'sides', 'finish', 'delivered', 'working', 'night', 'case', 'points', 'today', 'organization', 'recent', 'quite', 'show', 'des', 'areas', 'endorsement', 'edison', 'morning', 'interviewed', 'majorities', 'attendees', 'pat', 'piled', 'talking', 'months', 'definitely', 'hampshire', 'separated', 'supporters', 'order', 'kevin', 'powerful', 'blowouts', 'murphy', 'wears', 'davenport', 'caucused', 'addressing', 'afternoon', 'politics', 'several', 'work', 'spokesman', 'slowly', 'thought', 'comeback', 'must', 'proposals', 'contests', 'largest', 'weeks', 'caucusing', 'voters', 'achieving', 'sioux', 'lifted', 'ever', 'late', 'judge', 'fascinating', 'bacon', 'trump', 'next', 'woodbury', 'differential', 'lower', 'executive', 'solace', 'dominating', 'florida', 'bubble', 'actually', 'latino', 'march', 'community', 'lifetime', 'south', 'rubio', 'starkly', 'record', 'david', 'comprised', 'holds', 'firewall', 'tweets', 'supporter', 'iowa', 'given', 'organizing', 'never', 'predicted', 'advertised', 'shift', 'trounced', 'however', 'somewhat', 'arkansas', 'chip', 'identified', 'primary', 'able', 'keep', 'participants', 'fought', 'putting', 'bernie', 'christie', 'vice', 'recently', 'landscape', 'white', 'beat', 'statewide', 'would', 'among', 'go', 'advantage', 'broke', 'like', 'increased', 'bill', 'underestimating', 'come', 'took', 'finally', 'entrance', 'fourth', 'democrat', 'center', 'paper', 'better', 'cruz', 'clergy', 'three', 'contributing', 'line', 'tweeted', 'huckabee', 'live', 'goodbyes', 'know', 'time', 'mcguire', 'individual', 'released', 'caucus', 'strength', 'bless', 'carried', 'conservative', 'get', 'likely', 'competing', 'favoring', 'well', 'established', 'gop', 'implementing', 'sentiment', 'noble', 'polls', 'dominate', 'say', 'comparison', 'voice', 'homes', 'justin', 'predicting', 'hard', 'affluent', 'follow', 'strongly', 'friendly', 'sense', 'later', 'hillary', 'placed', 'place', 'quarters', 'house', 'turnout', 'caucusgoers', 'inspiring', 'intensified', 'tim', 'super', 'surprise', 'repeat', 'literally', 'money', 'virtual', 'came', 'sullivan', 'breathing', 'dallas', 'history', 'va', 'national', 'every', 'favored', 'edwards', 'give', 'review', 'parts', 'participated', 'questioning', 'twitter', 'accounted', 'scott', 'turned', 'race', 'reflecting', 'kid', 'lenski', 'neighborhood', 'beyond', 'solid', 'year', 'sorting', 'turnouts', 'media', 'second', 'ceded', 'hawk', 'jason', 'quipped', 'clayworth', 'shout', 'candidates', 'edged', 'event', 'call', 'wave', 'earners', 'sit', 'even', 'heavily', 'whose', 'primaries', 'nice', 'staffers', 'enthusiasm', 'meeting', 'republicans', 'moines', 'deserves', 'minnesota', 'kummer', 'country', 'two', 'fueled', 'new', 'hours', 'fight', 'suburban', 'iowans', 'prize', 'many', 'winning', 'mclean', 'presidential', 'experience', 'made', 'minority', 'arguing', 'drake', 'buttons', 'cases', 'communities', 'et', 'win', 'college', 'mark', 'jumps', 'seen', 'crisis', 'back', 'barely', 'may', 'told', 'game', 'republican', 'independents', 'effective', 'colorado', 'saying', 'granted', 'minds', 'people', 'massive', 'replicate', 'expects', 'sick', 'victories', 'rescuing', 'joe', 'support', 'flipped', 'denunciation', 'boy', 'rally', 'going', 'alabama', 'went', 'gang', 'former', 'nab', 'western', 'spotlight', 'backed', 'limits', 'activist', 'wooing', 'grasp', 'gone', 'take', 'hefty', 'staffer', 'blamed', 'batrice', 'filed', 'results', 'almost', 'times', 'shrugged', 'captured', 'includes', 'narrowest', 'tie', 'rynard', 'capitalized', 'cash', 'poll', 'leaders', 'projected', 'olmstead', 'percentage', 'put', 'final', 'weighed', 'concerns', 'senator', 'saving', 'obama', 'coming', 'lot', 'university', 'monday', 'allegiance', 'john', 'campaigning', 'landed', 'criticize', 'dynamics', 'exurban', 'one', 'serous', 'advance', 'less', 'husband', 'narrowed', 'observers', 'county', 'mike', 'great', 'getty', 'office', 'day', 'marco', 'instance', 'different', 'reports', 'began', 'make', 'sites', 'either', 'records', 'days', 'state', 'side', 'linn', 'warren', 'though', 'invested', 'ordinary', 'overwhelmingly', 'shock', 'campaign', 'entirely', 'successful', 'urban', 'afterward', 'month', 'long', 'home', 'seven', 'another', 'said', 'wealthier', 'council', 'thrilled', 'biggest', 'except', 'let', 'pressing', 'failed', 'martin', 'complained', 'nominee', 'victory', 'speaks', 'wife', 'polk', 'bit', 'story', 'nomination', 'could', 'little', 'unusual', 'backer', 'single', 'derailed', 'tonight', 'images', 'barack', 'momentum', 'dozens', 'achenbach', 'ask', 'audience', 'silence', 'black', 'expanded', 'end', 'encouraged', 'patty', 'ground', 'vermont', 'respectively', 'granite', 'makes', 'saw', 'eight', 'advocated', 'started', 'tuesday', 'key', 'saturday', 'third', 'choice', 'share', 'flips', 'hat', 'kept', 'votes', 'briggs', 'coalition', 'continue', 'within', 'blogger', 'jab', 'paid', 'dominated', 'northern', 'declared', 'week', 'fitzgerald', 'jasonnobledmr', 'done', 'video', 'vest', 'bid', 'unturned', 'top', 'including', 'election', 'everything', 'precinct', 'around', 'declare', 'disaffected', 'prospects', 'economy', 'tenure', 'success', 'field', 'rush', 'gracious', 'towns', 'supporting', 'close', 'sanders', 'early', 'margins', 'brighter', 'research', 'rapids', 'races', 'million', 'awake', 'twice', 'experts', 'bigger', 'chops', 'across', 'carolina', 'cnn', 'countered', 'governor', 'marched', 'competitive', 'eventually', 'hopeful', 'delegates', 'operation', 'democratic'}\n"
     ]
    }
   ],
   "source": [
    "entity = Entity('hillary clinton')\n",
    "entity.words = get_bag_of_words(entity)\n",
    "print(entity.words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use local file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter Data Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<twitter.api.Twitter object at 0x10432a208>\n"
     ]
    }
   ],
   "source": [
    "import twitter\n",
    "\n",
    "CONSUMER_KEY = \n",
    "CONSUMER_SECRET = \n",
    "OAUTH_TOKEN = \n",
    "OAUTH_TOKEN_SECRET = \n",
    "\n",
    "auth = twitter.oauth.OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET,\n",
    "                           CONSUMER_KEY, CONSUMER_SECRET)\n",
    "\n",
    "twitter_api = twitter.Twitter(auth=auth)\n",
    "\n",
    "print(twitter_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q = '#humanservices'\n",
    "search_results = twitter_api.search.tweets(q=q, count=100)\n",
    "statuses = search_results['statuses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "status_texts = [ status['text'] \n",
    "                 for status in statuses ]\n",
    "\n",
    "screen_names = [ user_mention['screen_name'] \n",
    "                 for status in statuses\n",
    "                     for user_mention in status['entities']['user_mentions'] ]\n",
    "\n",
    "hashtags = [ hashtag['text'] \n",
    "             for status in statuses\n",
    "                 for hashtag in status['entities']['hashtags'] ]\n",
    "\n",
    "# Compute a collection of all words from all tweets\n",
    "words = [ w \n",
    "          for t in status_texts \n",
    "              for w in t.split() if w.lower() not in stopwords.words('english') and w != \"RT\" and w != '&amp']\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('#humanservices', 37), ('#HumanServices', 33), ('@AccenturePubSvc:', 12), ('&amp;', 10), ('families', 8), ('leadership', 7), ('outcomes?', 5), ('digital', 5), ('leaders', 5), ('turn', 5), ('#childsupport', 5), ('Read', 5), ('https:…', 5), ('Check', 5), ('ideas', 5), ('questions', 4), ('@unitedwaychi', 4), ('w/', 4), ('State', 4), ('new', 4)]\n",
      "[('AccenturePubSvc', 12), ('unitedwaychi', 4), ('MsToya1913', 3), ('SDHumanServices', 2), ('UrbanCollegeBos', 1), ('Ostendorff', 1), ('DebMatheny', 1), ('MetroFamChicago', 1), ('SalArmyTampa', 1), ('UNG_News', 1), ('wiscjobs', 1), ('StevensonU', 1), ('SantaMonicaPD', 1), ('santamonicacity', 1), ('Bevhillsyeg', 1), ('johnkeypm', 1), ('RANDCorporation', 1), ('LETUHistory', 1), ('Jamie_Post', 1), ('amazon', 1)]\n",
      "[('humanservices', 41), ('HumanServices', 35), ('analytics', 6), ('childsupport', 5), ('Illinois', 4), ('health', 4), ('career', 3), ('1711FNDN', 3), ('1711humanservices', 3), ('director', 3), ('Analytics', 3), ('DevelopmentalDisabilities', 3), ('Grants', 3), ('MadisonWI', 2), ('SOS', 2), ('business', 2), ('mba', 2), ('SocialService', 2), ('Interoperability', 2), ('compliance', 2)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "for item in [words, screen_names, hashtags]:\n",
    "    c = Counter(item)\n",
    "    print(c.most_common()[:20]) # top 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+\n",
      "| Word              | Count |\n",
      "+-------------------+-------+\n",
      "| #humanservices    |    37 |\n",
      "| #HumanServices    |    33 |\n",
      "| @AccenturePubSvc: |    12 |\n",
      "| &amp;             |    10 |\n",
      "| families          |     8 |\n",
      "| leadership        |     7 |\n",
      "| outcomes?         |     5 |\n",
      "| digital           |     5 |\n",
      "| leaders           |     5 |\n",
      "| turn              |     5 |\n",
      "| #childsupport     |     5 |\n",
      "| Read              |     5 |\n",
      "| https:…           |     5 |\n",
      "| Check             |     5 |\n",
      "| ideas             |     5 |\n",
      "| questions         |     4 |\n",
      "| @unitedwaychi     |     4 |\n",
      "| w/                |     4 |\n",
      "| State             |     4 |\n",
      "| new               |     4 |\n",
      "+-------------------+-------+\n",
      "+-----------------+-------+\n",
      "| Screen Name     | Count |\n",
      "+-----------------+-------+\n",
      "| AccenturePubSvc |    12 |\n",
      "| unitedwaychi    |     4 |\n",
      "| MsToya1913      |     3 |\n",
      "| SDHumanServices |     2 |\n",
      "| UrbanCollegeBos |     1 |\n",
      "| Ostendorff      |     1 |\n",
      "| DebMatheny      |     1 |\n",
      "| MetroFamChicago |     1 |\n",
      "| SalArmyTampa    |     1 |\n",
      "| UNG_News        |     1 |\n",
      "| wiscjobs        |     1 |\n",
      "| StevensonU      |     1 |\n",
      "| SantaMonicaPD   |     1 |\n",
      "| santamonicacity |     1 |\n",
      "| Bevhillsyeg     |     1 |\n",
      "| johnkeypm       |     1 |\n",
      "| RANDCorporation |     1 |\n",
      "| LETUHistory     |     1 |\n",
      "| Jamie_Post      |     1 |\n",
      "| amazon          |     1 |\n",
      "+-----------------+-------+\n",
      "+---------------------------+-------+\n",
      "| Hashtag                   | Count |\n",
      "+---------------------------+-------+\n",
      "| humanservices             |    41 |\n",
      "| HumanServices             |    35 |\n",
      "| analytics                 |     6 |\n",
      "| childsupport              |     5 |\n",
      "| Illinois                  |     4 |\n",
      "| health                    |     4 |\n",
      "| career                    |     3 |\n",
      "| 1711FNDN                  |     3 |\n",
      "| 1711humanservices         |     3 |\n",
      "| director                  |     3 |\n",
      "| Analytics                 |     3 |\n",
      "| DevelopmentalDisabilities |     3 |\n",
      "| Grants                    |     3 |\n",
      "| MadisonWI                 |     2 |\n",
      "| SOS                       |     2 |\n",
      "| business                  |     2 |\n",
      "| mba                       |     2 |\n",
      "| SocialService             |     2 |\n",
      "| Interoperability          |     2 |\n",
      "| compliance                |     2 |\n",
      "+---------------------------+-------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "for label, data in (('Word', words), \n",
    "                    ('Screen Name', screen_names), \n",
    "                    ('Hashtag', hashtags)):\n",
    "    pt = PrettyTable(field_names=[label, 'Count']) \n",
    "    c = Counter(data)\n",
    "    [ pt.add_row(kv) for kv in c.most_common()[:20]]\n",
    "    pt.align[label], pt.align['Count'] = 'l', 'r' # Set column alignment\n",
    "    print(pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+----------------------------------------------------+\n",
      "| Count | Screen Name     | Text                                               |\n",
      "+-------+-----------------+----------------------------------------------------+\n",
      "| 4     | DebMatheny      | RT @DebMatheny: #Minnesota #ChildSexTrafficking    |\n",
      "|       |                 | #PedophiliaRing #CPS #HumanServices                |\n",
      "|       |                 | #CharitableFoundations! https://t.co/Fu1FfVrbvz    |\n",
      "|       |                 | https:/…                                           |\n",
      "| 3     | MsToya1913      | RT @MsToya1913: In #Illinois, real damage is being |\n",
      "|       |                 | done to our neediest children and families &amp;   |\n",
      "|       |                 | to our #humanservices @unitedwaychi                |\n",
      "|       |                 |                                                    |\n",
      "|       |                 | https:…                                            |\n",
      "| 3     | MsToya1913      | RT @MsToya1913: In #Illinois, real damage is being |\n",
      "|       |                 | done to our neediest children and families &amp;   |\n",
      "|       |                 | to our #humanservices @unitedwaychi                |\n",
      "|       |                 |                                                    |\n",
      "|       |                 | https:…                                            |\n",
      "| 3     | MsToya1913      | RT @MsToya1913: In #Illinois, real damage is being |\n",
      "|       |                 | done to our neediest children and families &amp;   |\n",
      "|       |                 | to our #humanservices @unitedwaychi                |\n",
      "|       |                 |                                                    |\n",
      "|       |                 | https:…                                            |\n",
      "| 3     | AccenturePubSvc | RT @AccenturePubSvc: Test yourself: Do you have    |\n",
      "|       |                 | the 5 traits of adaptive #HumanServices leaders?   |\n",
      "|       |                 | #HSSummit15 https://t.co/wVuSMfaDGm https:…        |\n",
      "+-------+-----------------+----------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "retweets = [\n",
    "            # Store out a tuple of these three values ...\n",
    "            (status['retweet_count'], \n",
    "             status['retweeted_status']['user']['screen_name'],\n",
    "             status['text']) \n",
    "            \n",
    "            # ... for each status ...\n",
    "            for status in statuses \n",
    "            \n",
    "            # ... so long as the status meets this condition.\n",
    "                if 'retweeted_status' in status\n",
    "           ]\n",
    "\n",
    "# Slice off the first 5 from the sorted results and display each item in the tuple\n",
    "\n",
    "pt = PrettyTable(field_names=['Count', 'Screen Name', 'Text'])\n",
    "[ pt.add_row(row) for row in sorted(retweets, reverse=True)[:5] ]\n",
    "pt.max_width['Text'] = 50\n",
    "pt.align= 'l'\n",
    "print(pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
